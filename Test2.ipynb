{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import resampy\n",
    "\n",
    "def extract_features(file_name):\n",
    "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_scaled = np.mean(mfccs.T, axis=0)\n",
    "    return mfccs_scaled\n",
    "\n",
    "def load_data(data_dir):\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for folder in ['lowSpeed', 'HighSpeed', 'Abnormal']:\n",
    "        folder_path = os.path.join(data_dir, folder)\n",
    "        for file in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            data = extract_features(file_path)\n",
    "            features.append(data)\n",
    "            labels.append(folder)\n",
    "    \n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "data_dir = './dataset/'\n",
    "X, y = load_data(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aae392f61dbb0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abnormal       1.00      1.00      1.00         2\n",
      "   HighSpeed       1.00      1.00      1.00         2\n",
      "    lowSpeed       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         6\n",
      "   macro avg       1.00      1.00      1.00         6\n",
      "weighted avg       1.00      1.00      1.00         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9275a627ab23c51c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sounddevice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msounddevice\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_live_sound\u001b[39m(model, duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, sample_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m22050\u001b[39m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sounddevice'"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def predict_live_sound(model, duration=5, sample_rate=22050):\n",
    "    print(\"Recording...\")\n",
    "    recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1)\n",
    "    # Plot the waveform\n",
    "    sd.wait()\n",
    "    \n",
    "    print(\"Recording complete.\")\n",
    "    # plt.figure(figsize=(10, 4))\n",
    "    # plt.plot(recording)\n",
    "    # plt.title(\"Live Audio Waveform\")\n",
    "    # plt.xlabel(\"Time\")\n",
    "    # plt.ylabel(\"Amplitude\")\n",
    "    # plt.show(block=False)\n",
    "    # plt.pause(0.1)  # Adjust this if the plot does not update properly\n",
    "    # plt.close()\n",
    "    # Extract features from the recorded audio\n",
    "    mfccs = librosa.feature.mfcc(y=recording.flatten(), sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_scaled = np.mean(mfccs.T, axis=0)\n",
    "    mfccs_scaled = mfccs_scaled.reshape(1, -1)\n",
    "    \n",
    "    # Predict the class\n",
    "    prediction = model.predict(mfccs_scaled)\n",
    "    print(\"Predicted class:\", prediction[0])\n",
    "\n",
    "# Example usage\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        predict_live_sound(clf)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopped by user.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
